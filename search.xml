<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于神经网络的语言模型（简单模型）</title>
      <link href="/blog/352722672.html"/>
      <url>/blog/352722672.html</url>
      
        <content type="html"><![CDATA[<h1 id="基于神经网络的语言模型（简单模型）"><a href="#基于神经网络的语言模型（简单模型）" class="headerlink" title="基于神经网络的语言模型（简单模型）"></a>基于神经网络的语言模型（简单模型）</h1><blockquote><p>本文主要为学习《自然语言处理：基于预训练模型的方法》第五章学习的总结，主要是使用全连接神经网络、循环神经网络来实现P(Xi|Xi-1Xi-2…Xi-m)</p></blockquote><h2 id="一、构建数据集"><a href="#一、构建数据集" class="headerlink" title="一、构建数据集"></a>一、构建数据集</h2><h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1.加载数据"></a>1.加载数据</h3><p>本次使用是NLTK包中提供的<code>reuters</code>语料库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_reuters</span>():</span><br><span class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> reuters</span><br><span class="line">    text = reuters.sents()</span><br><span class="line">    <span class="comment">#print(text[1])</span></span><br><span class="line">    text = [[word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> sentence] <span class="keyword">for</span> sentence <span class="keyword">in</span> text]</span><br><span class="line">    vocab = Vocab.build(text,reserved_tokens=[PAD_TOKEN,BOS_TOKEN,EOS_TOKEN])</span><br><span class="line">    corpus = [ vocab.covert_tokens_to_ids(sentence) <span class="keyword">for</span> sentence <span class="keyword">in</span> text]</span><br><span class="line">    <span class="keyword">return</span> corpus,vocab</span><br></pre></td></tr></table></figure><p>加载文本数据集，构建语料库类和词表类，并返回结果。</p>]]></content>
      
      
      <categories>
          
          <category> 自然语言处理 </category>
          
          <category> 语言模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自然语言处理 </tag>
            
            <tag> 语言模型 </tag>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于神经网络的简单文本分类（情感分类）总结</title>
      <link href="/blog/340717617.html"/>
      <url>/blog/340717617.html</url>
      
        <content type="html"><![CDATA[<h1 id="基于神经网络的简单文本分类（情感分类）总结"><a href="#基于神经网络的简单文本分类（情感分类）总结" class="headerlink" title="基于神经网络的简单文本分类（情感分类）总结"></a>基于神经网络的简单文本分类（情感分类）总结</h1><blockquote><p>本文主要为学习《自然语言处理：基于预训练模型的方法》第四章学习的总结</p></blockquote><h2 id="一、任务描述"><a href="#一、任务描述" class="headerlink" title="一、任务描述"></a>一、任务描述</h2><p>主要使用NLTK提供的句子倾向性分析数据（sentence_polarity）作为数据集，尝试使用多层感知机模型、卷积神经网络、循环神经网络、Transformer等模型应用在该数据集上，查看模型的分类效果。</p><!-- ![数据集一条sample的样式](https://img2023.cnblogs.com/blog/1203819/202303/1203819-20230328221127468-1249202682.png) --><div><!--块级封装-->    <center><!--将图片和文字居中-->    <img src="https://img2023.cnblogs.com/blog/1203819/202303/1203819-20230328221127468-1249202682.png" alt="无法显示图片时显示的文字" style="zoom:0.9">    <br><!--换行-->    数据集中一条sample的样式<!--标题-->    </center></div><h2 id="二、加载数据以及前期准备工作"><a href="#二、加载数据以及前期准备工作" class="headerlink" title="二、加载数据以及前期准备工作"></a>二、加载数据以及前期准备工作</h2><h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1.加载数据"></a>1.加载数据</h3><p>在NLTK中，提供了可以可以直接加载数据的API，直接按pos和neg两种标签加载数据，并划分前4000条为训练集，剩下的为测试集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_sentence_polarity</span>():</span><br><span class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> sentence_polarity</span><br><span class="line">    vocab = Vocab.build(sentence_polarity.sents())</span><br><span class="line">    <span class="built_in">print</span>(sentence_polarity.sents()[:<span class="number">1</span>])</span><br><span class="line">    train_data = [(vocab.covert_tokens_to_ids(sentence),<span class="number">0</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;pos&#x27;</span>)[:<span class="number">4000</span>]] \</span><br><span class="line">                    + [(vocab.covert_tokens_to_ids(sentence),<span class="number">1</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;neg&#x27;</span>)[:<span class="number">4000</span>]]</span><br><span class="line">    test_data = [(vocab.covert_tokens_to_ids(sentence),<span class="number">0</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;pos&#x27;</span>)[<span class="number">4000</span>:]] \</span><br><span class="line">                    + [(vocab.covert_tokens_to_ids(sentence),<span class="number">1</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;neg&#x27;</span>)[<span class="number">4000</span>:]]</span><br><span class="line">    <span class="comment">#print(len(train_data),len(test_data))</span></span><br><span class="line">    <span class="keyword">return</span> BowDataset(train_data),BowDataset(test_data),vocab </span><br></pre></td></tr></table></figure><h3 id="2-构建词表"><a href="#2-构建词表" class="headerlink" title="2.构建词表"></a>2.构建词表</h3><p>在自然语言处理中，我们可以把像词、字、字母这种处理单位统称为token，深度学习中训练过程多为数值计算，因此无法直接处理这些token。为此，对于每个token，我们需要为其赋予一个独有的索引值来代表这个token，这样才可以用于后续的学习训练。</p><p>为此，我们构建了<code>Vocab</code>词表类来为语料中所有出现过的token来赋予索引。<code>Vocab</code>类主要实现了以下几个功能：</p><ul><li>将一个token转化为对应的索引值</li><li>将一个token序列（即一句话）转化成索引值序列</li><li>通过索引值获得对应的token</li><li>读入语料库，为每个token赋予独有的索引值，同时为未登录词<code>&lt;unk&gt;</code>和填充词<code>&lt;pad&gt;</code>设置索引值。</li></ul><p>具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocab</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,tokens=<span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.idx_to_token = <span class="built_in">list</span>()</span><br><span class="line">        self.token_to_idx = <span class="built_in">dict</span>()</span><br><span class="line">        self.unk = <span class="string">&quot;&lt;unk&gt;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> tokens <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> self.unk <span class="keyword">not</span> <span class="keyword">in</span> tokens:</span><br><span class="line">                tokens = tokens + self.unk</span><br><span class="line">            <span class="keyword">for</span> token <span class="keyword">in</span> tokens:</span><br><span class="line">                self.idx_to_token.append(token)</span><br><span class="line">                self.token_to_idx[token] = <span class="built_in">len</span>(self.idx_to_token) - <span class="number">1</span></span><br><span class="line">        self.unk_idx = self.token_to_idx.get(self.unk)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">cls,text,min_freq=<span class="number">1</span>,reserved_tokens=<span class="literal">None</span></span>):</span><br><span class="line">        tokens_freq = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> text:</span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> sentence:</span><br><span class="line">                tokens_freq[word] += <span class="number">1</span></span><br><span class="line">        tokens = [<span class="string">&quot;&lt;unk&gt;&quot;</span>] + (reserved_tokens <span class="keyword">if</span> reserved_tokens <span class="keyword">else</span> [])</span><br><span class="line">        tokens += [token <span class="keyword">for</span> token,freq <span class="keyword">in</span> tokens_freq.items() </span><br><span class="line">                        <span class="keyword">if</span> freq&gt;=min_freq <span class="keyword">and</span> token != <span class="string">&quot;&lt;unk&gt;&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> cls(tokens)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.idx_to_token)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self,token</span>):</span><br><span class="line">        <span class="keyword">return</span> self.token_to_idx.get(token,self.unk_idx)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">covert_tokens_to_ids</span>(<span class="params">self,tokens</span>):</span><br><span class="line">        <span class="keyword">return</span> [self[token] <span class="keyword">for</span> token <span class="keyword">in</span> tokens]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">covert_ids_to_tokens</span>(<span class="params">self,indices</span>):</span><br><span class="line">        <span class="keyword">return</span> [self.idx_to_token[idx] <span class="keyword">for</span> idx <span class="keyword">in</span> indices]</span><br></pre></td></tr></table></figure><p>其中，<code>@classmethod</code>的作用是指定该方法为类方法，而不是实例方法。同时，被<code>@classmethod</code>传入的第一个参数可以是当前类。该修饰器的具体方法可以参考<br><a href="https://blog.csdn.net/leviopku/article/details/100745811">https://blog.csdn.net/leviopku/article/details/100745811</a></p><h3 id="3-构建数据集类"><a href="#3-构建数据集类" class="headerlink" title="3.构建数据集类"></a>3.构建数据集类</h3><h3 id="4-得到测试集和训练集"><a href="#4-得到测试集和训练集" class="headerlink" title="4.得到测试集和训练集"></a>4.得到测试集和训练集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_sentence_polarity</span>():</span><br><span class="line">    <span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> sentence_polarity</span><br><span class="line">    vocab = Vocab.build(sentence_polarity.sents())</span><br><span class="line">    <span class="built_in">print</span>(sentence_polarity.sents()[:<span class="number">1</span>])</span><br><span class="line">    train_data = [(vocab.covert_tokens_to_ids(sentence),<span class="number">0</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;pos&#x27;</span>)[:<span class="number">4000</span>]] \</span><br><span class="line">                    + [(vocab.covert_tokens_to_ids(sentence),<span class="number">1</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;neg&#x27;</span>)[:<span class="number">4000</span>]]</span><br><span class="line">    test_data = [(vocab.covert_tokens_to_ids(sentence),<span class="number">0</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;pos&#x27;</span>)[<span class="number">4000</span>:]] \</span><br><span class="line">                    + [(vocab.covert_tokens_to_ids(sentence),<span class="number">1</span>) <span class="keyword">for</span> sentence</span><br><span class="line">                    <span class="keyword">in</span> sentence_polarity.sents(categories=<span class="string">&#x27;neg&#x27;</span>)[<span class="number">4000</span>:]]</span><br><span class="line">    <span class="comment">#print(len(train_data),len(test_data))</span></span><br><span class="line">    <span class="keyword">return</span> BowDataset(train_data),BowDataset(test_data),vocab </span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/blog/1243066710.html"/>
      <url>/blog/1243066710.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
